{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Heuristic\n",
    "import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(env, H,observation,K,A,N_SAMPLES,vision,epsilon):  \n",
    "    grid, pos, remain_steps= observation\n",
    "    actions= env.available_actions(pos)   \n",
    "    NEXT_STEPS=ITERABLE_STEPS(env,H,actions)\n",
    "    q_values={}\n",
    "    for action_step in NEXT_STEPS:       \n",
    "        action_s, q_value= Simulation(action_step,K,A,N_SAMPLES,vision)        \n",
    "        q_values[action_s]=q_value   \n",
    "    if random.random() > epsilon:\n",
    "        print(\"Explotation\")\n",
    "        #Maximization over all possible action controls (max u_xk)\n",
    "        action_max= max(q_values.keys(), key=(lambda k: q_values[k]))\n",
    "    else:\n",
    "        print(\"Exploration\")\n",
    "        action_max=random.choice(list(q_values.keys()))   \n",
    "    return(action_max,q_values[action_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITERABLE_STEPS():\n",
    "    def __init__(self,env, H, actions):\n",
    "        self.enviroment=env\n",
    "        self.H_ref = H      \n",
    "        self.actions = actions\n",
    "        self.index = 0\n",
    "        self.TOP = len(actions)\n",
    "        return None\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index == self.TOP:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            i = self.index\n",
    "            self.index += 1\n",
    "            return (Copy(self.enviroment), self.actions[i], self.H_ref)     \n",
    "\n",
    "    def __del__(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simulation(simulation_args,K,A,N_SAMPLES,vision):    \n",
    "    total_q_value=0\n",
    "    alpha=A\n",
    "    env_c, action, H = simulation_args  \n",
    "    #Make first step(1-step-lookahead deterministic)\n",
    "    observation, g_k, done, info = env_c.step(action)\n",
    "    checkpoint = env_c.make_checkpoint()\n",
    "    total_q_value=0   \n",
    "    #Follow the heuristic K-steps   \n",
    "    for n_samples in range(N_SAMPLES):        \n",
    "        t_cost=0\n",
    "        q_value=0        \n",
    "        env_c.load_checkpoint(checkpoint)      \n",
    "        for r_iter in range(K):                \n",
    "                action_H = H(observation,vision) \n",
    "                observation, cost, done, info = env_c.step(action_H)                \n",
    "                cost=cost*alpha \n",
    "                alpha=alpha*A\n",
    "                t_cost=t_cost + cost               \n",
    "        q_value=g_k+t_cost #q-value for one sample\n",
    "        total_q_value=total_q_value+q_value #Adding up values of N_SAMPLES               \n",
    "    total_q_value=total_q_value/N_SAMPLES #Average of q value cost over all samples   \n",
    "    del env_c\n",
    "    return (action,total_q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Copy(env):\n",
    "    n_env = helicopter.EnvMakerForestFire(init_pos_row=env.pos_row,init_pos_col=env.pos_col,n_row = env.n_row, n_col = env.n_col,\n",
    "                                          p_tree = env.p_tree, p_fire =env.p_fire, moves_before_updating = env.moves_before_updating,\n",
    "                                          reward_type = env.reward_type, reward_tree = env.reward_tree,reward_fire = env.reward_fire,\n",
    "                                          reward_empty =env.reward_empty, reward_hit = env.reward_hit,sub_tree = env.sub_tree,\n",
    "                                          sub_empty = env.sub_empty, sub_fire = env.sub_fire, sub_rock = env.sub_rock,sub_lake = env.sub_lake,\n",
    "                                          ip_tree = env.ip_tree, ip_empty =env.ip_empty, ip_fire =env.ip_fire, ip_rock = env.ip_rock,\n",
    "                                          ip_lake = env.ip_lake)\n",
    "    n_env.grid = copy.deepcopy(env.grid)      \n",
    "    n_env.total_reward = copy.deepcopy(env.total_reward)   \n",
    "    n_env.total_hits=copy.deepcopy(env.total_hits)\n",
    "    n_env.remaining_moves=copy.deepcopy(env.remaining_moves)\n",
    "    \n",
    "    return n_env"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
